{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import tweepy\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key = \"TM6dANbzBL5LzpXox05KJePwy\"\n",
    "consumer_secret = \"HV3nuTA82M1tjTE2sKTeKPZ8kWDi5r4EgUGE4ogroinPcmfPqe\"\n",
    "access_key = \"921130974569811968-RcDUIosERaFWnHHYw5C6OSq4aAGYdKi\"\n",
    "access_secret = \"AOPClE7TtSHMuO8Jbs4TNhdxfEfPK5s3cbwnJpCE3s2v3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtener_tweets(nombre):\n",
    "    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_key, access_secret)\n",
    "    api = tweepy.API(auth)\n",
    "    \n",
    "    corpus_tweets = []\n",
    "    batch_tweet = api.user_timeline(nombre,count=200)\n",
    "    corpus_tweets.extend(batch_tweet)\n",
    "    \n",
    "    index_lst_tweet= batch_tweet[-1].id-1\n",
    "    l_b_n=len(api.user_timeline(nombre,count=200,max_id=index_lst_tweet))\n",
    "    \n",
    "    while (True):\n",
    "        batch_tweet = api.user_timeline(nombre,count=200,max_id=index_lst_tweet)\n",
    "        corpus_tweets.extend(batch_tweet)\n",
    "        if (len(batch_tweet)==0):\n",
    "            break\n",
    "        index_lst_tweet= batch_tweet[-1].id-1\n",
    "    return corpus_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genarate_corpus(name_corpus,df):\n",
    "    fo = open(name_corpus, \"w\")\n",
    "    for i in df['Tweet']:\n",
    "        (fo.write((i).decode(\"utf-8\")+\"\\n\"))\n",
    "    fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualizacion_anio(df):\n",
    "    counts = df['Fecha'].value_counts(sort=False)\n",
    "    plt.bar(counts.index,counts)\n",
    "    plt.title('Tweets por AÃ±o')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    #Se obtienen los tweets\n",
    "    nombre_ob_tweets=\"vicentefoxque\"\n",
    "    corpus_tweets = obtener_tweets(nombre_ob_tweets)\n",
    "    \n",
    "    #Se quitan los RT\n",
    "    corpus_tweets_filtrados = [[tt.id_str, tt.created_at, tt.text.encode(\"utf-8\")] for tt in corpus_tweets if 'RT @' not in tt.text ]\n",
    "    \n",
    "    #Se construye un DataFrame con los campos de : 'ID','Fecha','Tweet'\n",
    "    df = pd.DataFrame(corpus_tweets_filtrados,columns=['ID','Fecha','Tweet'])\n",
    "    df['Fecha']=df['Fecha'].apply(lambda x:x.strftime('%Y'))\n",
    "    \n",
    "    # Un top 5 del DataFrame\n",
    "    print (df.head(5))\n",
    "    # Tweets por anio.\n",
    "    visualizacion_anio(df)\n",
    "    \n",
    "    # Se guarda el dataframe en un CSV. \n",
    "    df.to_csv(\"Tweets_Hist_\"+nombre_ob_tweets+\".csv\", sep='\\t', encoding='utf-8')\n",
    "    \n",
    "    # Se genera el corpus\n",
    "    genarate_corpus(\"Corpus_Tweets_\"+nombre_ob_tweets+\".txt\",df)\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
